{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression using StandardScaler vs MinMaxScaler for scaling y val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class Data(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "        self.len = self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearReg(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(LinearReg,self).__init__()\n",
    "        self.layer = nn.Linear(input_dim,output_dim)\n",
    "        print(self.layer.weight)\n",
    "        print(self.layer.bias)\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = self.layer(X) # layer has the w and b (random at start)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples= 1000, n_features= 2, n_informative= 2, n_targets= 1, noise= 30, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_test = scaler_y.transform(y_test.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = Data(X_train,y_train)\n",
    "testdata = Data(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "num_workers = 0\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    traindata,\n",
    "    batch_size = batch_size, \n",
    "    shuffle = True, \n",
    "    num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.0435, 0.5273]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0418], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr = 0.01\n",
    "X_dim = X_train.shape[1]\n",
    "y_dim = y_train.shape[1] if len(y_train.shape) > 1 else 1\n",
    "model = LinearReg(X_dim,y_dim)\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:   10 | Batches per epoch:  13 | Loss: 0.1146976724\n",
      "Epochs:   20 | Batches per epoch:  13 | Loss: 0.1102002716\n",
      "Epochs:   30 | Batches per epoch:  13 | Loss: 0.1084873120\n",
      "Epochs:   40 | Batches per epoch:  13 | Loss: 0.1084082602\n",
      "Epochs:   50 | Batches per epoch:  13 | Loss: 0.1078679000\n",
      "Epochs:   60 | Batches per epoch:  13 | Loss: 0.1091840600\n",
      "Epochs:   70 | Batches per epoch:  13 | Loss: 0.1104319216\n",
      "Epochs:   80 | Batches per epoch:  13 | Loss: 0.1084396186\n",
      "Epochs:   90 | Batches per epoch:  13 | Loss: 0.1069400482\n",
      "Epochs:  100 | Batches per epoch:  13 | Loss: 0.1081726161\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i,(xi, yi) in enumerate(train_loader):\n",
    "        outputs = model(xi)\n",
    "        yi = yi.view(-1,1) # done to match the output shape\n",
    "        \n",
    "        loss = criterion(outputs,yi)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param -= lr * param.grad\n",
    "\n",
    "        # optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    if not ((epoch + 1) % (epochs // 10)):\n",
    "        print(f'Epochs:{epoch + 1:5d} | ' \\\n",
    "            f'Batches per epoch: {i + 1:3d} | ' \\\n",
    "            f'Loss: {running_loss / (i + 1):.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9008026435059427"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,ypred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24817594646872024"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,ypred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10280250739739649"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,ypred.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_test = scaler_y.transform(y_test.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = Data(X_train,y_train)\n",
    "testdata = Data(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "num_workers = 0\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    traindata,\n",
    "    batch_size = batch_size, \n",
    "    shuffle = True, \n",
    "    num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4001, -0.3783]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4122], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr = 0.01\n",
    "X_dim = X_train.shape[1]\n",
    "y_dim = y_train.shape[1] if len(y_train.shape) > 1 else 1\n",
    "model = LinearReg(X_dim,y_dim)\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:   10 | Batches per epoch:  13 | Loss: 0.0109123116\n",
      "Epochs:   20 | Batches per epoch:  13 | Loss: 0.0032261905\n",
      "Epochs:   30 | Batches per epoch:  13 | Loss: 0.0032324750\n",
      "Epochs:   40 | Batches per epoch:  13 | Loss: 0.0031755640\n",
      "Epochs:   50 | Batches per epoch:  13 | Loss: 0.0031834805\n",
      "Epochs:   60 | Batches per epoch:  13 | Loss: 0.0031587689\n",
      "Epochs:   70 | Batches per epoch:  13 | Loss: 0.0032177895\n",
      "Epochs:   80 | Batches per epoch:  13 | Loss: 0.0032254524\n",
      "Epochs:   90 | Batches per epoch:  13 | Loss: 0.0032235899\n",
      "Epochs:  100 | Batches per epoch:  13 | Loss: 0.0032200247\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i,(xi, yi) in enumerate(train_loader):\n",
    "        outputs = model(xi)\n",
    "        yi = yi.view(-1,1) # done to match the output shape\n",
    "        \n",
    "        loss = criterion(outputs,yi)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param -= lr * param.grad\n",
    "\n",
    "        # optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    if not ((epoch + 1) % (epochs // 10)):\n",
    "        print(f'Epochs:{epoch + 1:5d} | ' \\\n",
    "            f'Batches per epoch: {i + 1:3d} | ' \\\n",
    "            f'Loss: {running_loss / (i + 1):.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9009169793642788"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,ypred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04258436561800623"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,ypred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003026536834517021"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,ypred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
